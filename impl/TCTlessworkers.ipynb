{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__import des librairies nécessaires__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "#from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__import des autres fichiers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Theo/Documents/Dépots Githubs/2023/chocoEA/impl\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Theo/Documents/Dépots Githubs/2023/chocoEA\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nv_orga.Models import Net, Net_eNTK\n",
    "from nv_orga.FedAvg import average_models,client_update\n",
    "from nv_orga.Eval import evaluate_many_models\n",
    "from nv_orga.NTK import client_compute_eNTK\n",
    "from nv_orga.Scaffold import scaffold_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__définition des hyperparamètres__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'num_client_stage1_2': 2,\n",
    "    'num_client_stage3': 5,\n",
    "    'seed': 123,\n",
    "    'num_samples_per_client': 500,\n",
    "    'rounds_stage1': 100, #100 de base\n",
    "    'local_epochs_stage1': 5,\n",
    "    'mini_batchsize_stage1': 64,\n",
    "    'local_lr_stage1': 0.1,\n",
    "    'rounds_stage2': 1, #100 de base\n",
    "    'local_steps_stage2': 100,\n",
    "    'local_lr_stage2': 0.001,\n",
    "    'rounds_stage3': 100,\n",
    "    'local_steps_stage3': 100,\n",
    "    'local_lr_stage3': 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__création d'un dossier de sauvegarde pour les modèles successifs du stage 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "isExist = os.path.exists('data/ckpt_stage1')\n",
    "if not isExist:\n",
    "   os.makedirs('data/ckpt_stage1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Stage 1__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __hyperparamètres__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients_stage1_2 = args[\"num_client_stage1_2\"]\n",
    "num_clients_stage3 = args[\"num_client_stage3\"]\n",
    "num_rounds_stage1 = args[\"rounds_stage1\"]\n",
    "\n",
    "epochs_stage1 = args[\"local_epochs_stage1\"]\n",
    "batch_size_stage1 = args[\"mini_batchsize_stage1\"]\n",
    "lr_stage1 = args[\"local_lr_stage1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __création des datasets décentralisés (ie non idd)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load les data MNIST, les transformer en tensor et les normaliser\n",
    "traindata = datasets.MNIST('data/data_mnist', train=True, download=True,\n",
    "                           transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                         transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "\n",
    "target_labels = torch.stack([traindata.targets == i for i in range(10)]) # 10 x 60000 (one-hot qui détermine la label correpondant à la ligne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels_split = []\n",
    "torch.manual_seed(args[\"seed\"]) # pour que les splits soient les mêmes à chaque fois\n",
    "torch.cuda.manual_seed(args[\"seed\"])  # pour que les splits soient les mêmes à chaque fois\n",
    "\n",
    "for i in range(num_clients_stage3):\n",
    "    index_split = torch.where(target_labels[(2 * i):(2 * (i + 1))].sum(0))[0] # on prend les labels 2i et 2i+1\n",
    "    perm_split = torch.randperm(index_split.size(0)) # on mélange les indices\n",
    "    index_split_subsample = index_split[perm_split[:args[\"num_samples_per_client\"]]] # on prend les 500 premiers\n",
    "    target_labels_split += [index_split_subsample] # on ajoute à la liste des labels splités\n",
    "\n",
    "#Chacun des 5 clients reçoit 500 images d'un des deux labels associés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training datasets (subsampled)\n",
    "traindata_split = [torch.utils.data.Subset(traindata, tl) for tl in target_labels_split] # chaque élément contient les images et labels d'un client\n",
    "train_loader = [torch.utils.data.DataLoader(train_subset, batch_size=batch_size_stage1, shuffle=True)\n",
    "                for train_subset in traindata_split] # on crée les dataloader associés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __création du dataset global de test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset (subsampled)\n",
    "testdata = datasets.MNIST('data/data_mnist', train=False,\n",
    "                          transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                        transforms.Normalize((0.1307,), (0.3081,))])) # on charge les données de test\n",
    "\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "torch.cuda.manual_seed(args[\"seed\"])\n",
    "perm_split_test = torch.randperm(testdata.targets.shape[0])\n",
    "testdata_subset = torch.utils.data.Subset(testdata, perm_split_test[:1000])\n",
    "test_loader = torch.utils.data.DataLoader(testdata_subset, batch_size=batch_size_stage1, shuffle=False) #pas de shuffle pour le test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __modèle de réseau de neurones de base__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = Net() #modifié depuis Net().cuda() #Modèle fédéré\n",
    "client_models = [Net() for _ in range(num_clients_stage3)] #modifié depuis Net().cuda() #Modèles des clients\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "opt = [optim.SGD(model.parameters(), lr=lr_stage1) for model in client_models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __imple de FedAvg__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run TCT-Stage1 (i.e., FedAvg)\n",
    "# for r in range(num_rounds_stage1):\n",
    "#     # load global weights\n",
    "#     for model in client_models[:num_clients_stage1_2]:\n",
    "#         model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "#     # client update\n",
    "#     loss = 0\n",
    "#     for i in range(num_clients_stage1_2):\n",
    "#         loss += client_update(client_models[i], opt[i], train_loader[i], epoch=epochs_stage1)\n",
    "\n",
    "#     # average params across neighbors\n",
    "#     average_models(global_model, client_models[:num_clients_stage1_2])\n",
    "\n",
    "#     # evaluate\n",
    "#     test_losses, accuracies = evaluate_many_models(client_models[:num_clients_stage1_2], test_loader)\n",
    "#     torch.save(client_models[0].state_dict(), 'data/ckpt_stage1/stage1_100rounds_3workers.pth')\n",
    "\n",
    "#     print('%d-th round: average train loss %0.3g | average test loss %0.3g | average test acc: %0.3f' % (\n",
    "#     r, loss / num_clients_stage1_2, test_losses.mean(), accuracies.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Stage 2__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __hyperparamètres__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds_stage2 = args[\"rounds_stage2\"]\n",
    "batch_size = args[\"num_samples_per_client\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __modèle eNTK__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n"
     ]
    }
   ],
   "source": [
    "# Init and load model ckpt\n",
    "global_model = Net_eNTK() #supprimer .cuda()\n",
    "global_model.load_state_dict(torch.load('data/ckpt_stage1/stage1_100rounds_3workers.pth'))\n",
    "global_model.fc2 = nn.Linear(128, 1) #supprimer .cuda() #récupérer une unique sortie ici #supprimer le dernier layer pour le remplacer (passer de 128->10 à 128->1)\n",
    "print('load model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Compute eNTK__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 573.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 64/64 [00:00<00:00, 727.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "grad_all = []\n",
    "target_all = []\n",
    "target_onehot_all = []\n",
    "for i in range(num_clients_stage1_2):\n",
    "    grad_i, target_onehot_i, target_i = client_compute_eNTK(global_model, train_loader[i])\n",
    "    grad_all.append(copy.deepcopy(grad_i).cpu())\n",
    "    target_all.append(copy.deepcopy(target_i).cpu())\n",
    "    target_onehot_all.append(copy.deepcopy(target_onehot_i).cpu())\n",
    "    del grad_i\n",
    "    del target_onehot_i\n",
    "    del target_i\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_all[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 661.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "grad_eval, target_eval_onehot, target_eval  = client_compute_eNTK(global_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __run stage 2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/1xnjycd57cjdlfxk8s7k719c0000gn/T/ipykernel_91941/2973467877.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta_global = torch.tensor(theta_global, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "# Init linear models\n",
    "theta_global = torch.zeros(100000, 10) #supprimer .cuda()\n",
    "theta_global = torch.tensor(theta_global, requires_grad=False)\n",
    "client_thetas = [torch.zeros_like(theta_global) for _ in range(num_clients_stage3)] #supprimer .cuda()\n",
    "client_hi_s = [torch.zeros_like(theta_global) for _ in range(num_clients_stage3)] #supprimer .cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0: train accuracy=0.8125 test accuracy=0.21875\n"
     ]
    }
   ],
   "source": [
    "# Run TCT-Stage2\n",
    "for round_idx in range(num_rounds_stage2):\n",
    "    theta_list = []\n",
    "    for i in range(num_clients_stage1_2):\n",
    "        theta_hat_update, h_i_client_update = scaffold_update(grad_all[i],\n",
    "                                                              target_all[i],\n",
    "                                                              client_thetas[i],\n",
    "                                                              client_hi_s[i],\n",
    "                                                              theta_global,\n",
    "                                                              M=args[\"local_steps_stage2\"],\n",
    "                                                              lr_local=args[\"local_lr_stage2\"])\n",
    "        client_hi_s[i] = h_i_client_update * 1.0\n",
    "        client_thetas[i] = theta_hat_update * 1.0\n",
    "        theta_list.append(theta_hat_update)\n",
    "\n",
    "    # averaging\n",
    "    theta_global = torch.zeros_like(theta_list[0]) #supprimer .cuda()\n",
    "    for theta_idx in range(num_clients_stage1_2):\n",
    "        theta_global += (1.0 / num_clients_stage1_2) * theta_list[theta_idx]\n",
    "\n",
    "    # eval on train\n",
    "    logits_class_train = torch.cat(grad_all) @ theta_global #supprimer .cuda()\n",
    "    _, targets_pred_train = logits_class_train.max(1)\n",
    "    train_acc = targets_pred_train.eq(torch.cat(target_all)).sum() / (1.0 * logits_class_train.shape[0]) #supprimer .cuda()\n",
    "    # eval on test\n",
    "    logits_class_test = grad_eval @ theta_global\n",
    "    _, targets_pred_test = logits_class_test.max(1)\n",
    "    test_acc = targets_pred_test.eq(target_eval).sum() / (1.0 * logits_class_test.shape[0]) #supprimer .cuda()\n",
    "    print('Round %d: train accuracy=%0.5g test accuracy=%0.5g' % (round_idx, train_acc.item(), test_acc.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "num_rounds_stage3 = args[\"rounds_stage3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 731.62it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 793.88it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 779.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#Compute NTK\n",
    "for i in range(num_clients_stage1_2, num_clients_stage3):\n",
    "    grad_i, target_onehot_i, target_i = client_compute_eNTK(global_model, train_loader[i])\n",
    "    grad_all.append(copy.deepcopy(grad_i).cpu())\n",
    "    target_all.append(copy.deepcopy(target_i).cpu())\n",
    "    target_onehot_all.append(copy.deepcopy(target_onehot_i).cpu())\n",
    "    del grad_i\n",
    "    del target_onehot_i\n",
    "    del target_i\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0: train accuracy=0.33125 test accuracy=0.23438\n",
      "Round 1: train accuracy=0.34688 test accuracy=0.28125\n",
      "Round 2: train accuracy=0.36562 test accuracy=0.28125\n",
      "Round 3: train accuracy=0.4 test accuracy=0.28125\n",
      "Round 4: train accuracy=0.425 test accuracy=0.28125\n",
      "Round 5: train accuracy=0.44688 test accuracy=0.29688\n",
      "Round 6: train accuracy=0.4625 test accuracy=0.32812\n",
      "Round 7: train accuracy=0.49687 test accuracy=0.39062\n",
      "Round 8: train accuracy=0.51562 test accuracy=0.4375\n",
      "Round 9: train accuracy=0.54062 test accuracy=0.46875\n",
      "Round 10: train accuracy=0.55313 test accuracy=0.5\n",
      "Round 11: train accuracy=0.57187 test accuracy=0.48438\n",
      "Round 12: train accuracy=0.58438 test accuracy=0.5\n",
      "Round 13: train accuracy=0.60625 test accuracy=0.51562\n",
      "Round 14: train accuracy=0.62813 test accuracy=0.51562\n",
      "Round 15: train accuracy=0.6375 test accuracy=0.53125\n",
      "Round 16: train accuracy=0.64375 test accuracy=0.5625\n",
      "Round 17: train accuracy=0.65 test accuracy=0.5625\n",
      "Round 18: train accuracy=0.65625 test accuracy=0.5625\n",
      "Round 19: train accuracy=0.65625 test accuracy=0.5625\n",
      "Round 20: train accuracy=0.65625 test accuracy=0.5625\n",
      "Round 21: train accuracy=0.66875 test accuracy=0.57812\n",
      "Round 22: train accuracy=0.67188 test accuracy=0.57812\n",
      "Round 23: train accuracy=0.675 test accuracy=0.57812\n",
      "Round 24: train accuracy=0.67813 test accuracy=0.57812\n",
      "Round 25: train accuracy=0.68437 test accuracy=0.59375\n",
      "Round 26: train accuracy=0.6875 test accuracy=0.59375\n",
      "Round 27: train accuracy=0.69375 test accuracy=0.59375\n",
      "Round 28: train accuracy=0.70625 test accuracy=0.59375\n",
      "Round 29: train accuracy=0.70938 test accuracy=0.59375\n",
      "Round 30: train accuracy=0.71562 test accuracy=0.59375\n",
      "Round 31: train accuracy=0.71875 test accuracy=0.60938\n",
      "Round 32: train accuracy=0.725 test accuracy=0.60938\n",
      "Round 33: train accuracy=0.72812 test accuracy=0.60938\n",
      "Round 34: train accuracy=0.74063 test accuracy=0.625\n",
      "Round 35: train accuracy=0.74063 test accuracy=0.625\n",
      "Round 36: train accuracy=0.74375 test accuracy=0.625\n",
      "Round 37: train accuracy=0.74687 test accuracy=0.625\n",
      "Round 38: train accuracy=0.74687 test accuracy=0.625\n",
      "Round 39: train accuracy=0.74687 test accuracy=0.625\n",
      "Round 40: train accuracy=0.74687 test accuracy=0.625\n",
      "Round 41: train accuracy=0.75 test accuracy=0.625\n",
      "Round 42: train accuracy=0.74687 test accuracy=0.625\n",
      "Round 43: train accuracy=0.75313 test accuracy=0.625\n",
      "Round 44: train accuracy=0.75625 test accuracy=0.64062\n",
      "Round 45: train accuracy=0.75937 test accuracy=0.64062\n",
      "Round 46: train accuracy=0.7625 test accuracy=0.64062\n",
      "Round 47: train accuracy=0.7625 test accuracy=0.64062\n",
      "Round 48: train accuracy=0.76562 test accuracy=0.64062\n",
      "Round 49: train accuracy=0.76875 test accuracy=0.64062\n",
      "Round 50: train accuracy=0.775 test accuracy=0.64062\n",
      "Round 51: train accuracy=0.77812 test accuracy=0.64062\n",
      "Round 52: train accuracy=0.79062 test accuracy=0.64062\n",
      "Round 53: train accuracy=0.79062 test accuracy=0.65625\n",
      "Round 54: train accuracy=0.79062 test accuracy=0.65625\n",
      "Round 55: train accuracy=0.79688 test accuracy=0.65625\n",
      "Round 56: train accuracy=0.8 test accuracy=0.65625\n",
      "Round 57: train accuracy=0.8 test accuracy=0.65625\n",
      "Round 58: train accuracy=0.8 test accuracy=0.65625\n",
      "Round 59: train accuracy=0.80313 test accuracy=0.65625\n",
      "Round 60: train accuracy=0.80313 test accuracy=0.65625\n",
      "Round 61: train accuracy=0.80313 test accuracy=0.65625\n",
      "Round 62: train accuracy=0.80625 test accuracy=0.67188\n",
      "Round 63: train accuracy=0.80625 test accuracy=0.6875\n",
      "Round 64: train accuracy=0.80625 test accuracy=0.6875\n",
      "Round 65: train accuracy=0.80625 test accuracy=0.6875\n",
      "Round 66: train accuracy=0.80625 test accuracy=0.6875\n",
      "Round 67: train accuracy=0.80625 test accuracy=0.6875\n",
      "Round 68: train accuracy=0.80625 test accuracy=0.6875\n",
      "Round 69: train accuracy=0.80625 test accuracy=0.6875\n",
      "Round 70: train accuracy=0.80625 test accuracy=0.70312\n",
      "Round 71: train accuracy=0.80625 test accuracy=0.70312\n",
      "Round 72: train accuracy=0.8125 test accuracy=0.70312\n",
      "Round 73: train accuracy=0.81563 test accuracy=0.70312\n",
      "Round 74: train accuracy=0.81875 test accuracy=0.70312\n",
      "Round 75: train accuracy=0.81875 test accuracy=0.70312\n",
      "Round 76: train accuracy=0.81875 test accuracy=0.70312\n",
      "Round 77: train accuracy=0.81875 test accuracy=0.70312\n",
      "Round 78: train accuracy=0.825 test accuracy=0.70312\n",
      "Round 79: train accuracy=0.82812 test accuracy=0.70312\n",
      "Round 80: train accuracy=0.83125 test accuracy=0.70312\n",
      "Round 81: train accuracy=0.83438 test accuracy=0.70312\n",
      "Round 82: train accuracy=0.8375 test accuracy=0.70312\n",
      "Round 83: train accuracy=0.8375 test accuracy=0.70312\n",
      "Round 84: train accuracy=0.8375 test accuracy=0.71875\n",
      "Round 85: train accuracy=0.84062 test accuracy=0.71875\n",
      "Round 86: train accuracy=0.84375 test accuracy=0.71875\n",
      "Round 87: train accuracy=0.84375 test accuracy=0.73438\n",
      "Round 88: train accuracy=0.84375 test accuracy=0.75\n",
      "Round 89: train accuracy=0.85 test accuracy=0.75\n",
      "Round 90: train accuracy=0.85312 test accuracy=0.75\n",
      "Round 91: train accuracy=0.85312 test accuracy=0.75\n",
      "Round 92: train accuracy=0.85625 test accuracy=0.75\n",
      "Round 93: train accuracy=0.86875 test accuracy=0.75\n",
      "Round 94: train accuracy=0.87187 test accuracy=0.75\n",
      "Round 95: train accuracy=0.87187 test accuracy=0.75\n",
      "Round 96: train accuracy=0.87187 test accuracy=0.75\n",
      "Round 97: train accuracy=0.875 test accuracy=0.75\n",
      "Round 98: train accuracy=0.875 test accuracy=0.75\n",
      "Round 99: train accuracy=0.875 test accuracy=0.75\n"
     ]
    }
   ],
   "source": [
    "##Stage 3\n",
    "# Run TCT-Stage2\n",
    "for round_idx in range(num_rounds_stage3):\n",
    "    theta_list = []\n",
    "    for i in range(num_clients_stage3):\n",
    "        theta_hat_update, h_i_client_update = scaffold_update(grad_all[i],\n",
    "                                                              target_all[i],\n",
    "                                                              client_thetas[i],\n",
    "                                                              client_hi_s[i],\n",
    "                                                              theta_global,\n",
    "                                                              M=args[\"local_steps_stage2\"],\n",
    "                                                              lr_local=args[\"local_lr_stage2\"])\n",
    "        client_hi_s[i] = h_i_client_update * 1.0\n",
    "        client_thetas[i] = theta_hat_update * 1.0\n",
    "        theta_list.append(theta_hat_update)\n",
    "\n",
    "    # averaging\n",
    "    theta_global = torch.zeros_like(theta_list[0]) #supprimer .cuda()\n",
    "    for theta_idx in range(num_clients_stage3):\n",
    "        theta_global += (1.0 / num_clients_stage3) * theta_list[theta_idx]\n",
    "\n",
    "    # eval on train\n",
    "    logits_class_train = torch.cat(grad_all) @ theta_global #supprimer .cuda()\n",
    "    _, targets_pred_train = logits_class_train.max(1)\n",
    "    train_acc = targets_pred_train.eq(torch.cat(target_all)).sum() / (1.0 * logits_class_train.shape[0]) #supprimer .cuda()\n",
    "    # eval on test\n",
    "    logits_class_test = grad_eval @ theta_global\n",
    "    _, targets_pred_test = logits_class_test.max(1)\n",
    "    test_acc = targets_pred_test.eq(target_eval).sum() / (1.0 * logits_class_test.shape[0]) #supprimer .cuda()\n",
    "    print('Round %d: train accuracy=%0.5g test accuracy=%0.5g' % (round_idx, train_acc.item(), test_acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 10: train accuracy=0.87813 test accuracy=0.75\n",
      "Round 11: train accuracy=0.87813 test accuracy=0.75\n",
      "Round 12: train accuracy=0.88125 test accuracy=0.75\n",
      "Round 13: train accuracy=0.88125 test accuracy=0.75\n",
      "Round 14: train accuracy=0.88125 test accuracy=0.75\n",
      "Round 15: train accuracy=0.88125 test accuracy=0.75\n",
      "Round 16: train accuracy=0.88125 test accuracy=0.75\n",
      "Round 17: train accuracy=0.88437 test accuracy=0.75\n",
      "Round 18: train accuracy=0.88437 test accuracy=0.75\n",
      "Round 19: train accuracy=0.88437 test accuracy=0.75\n",
      "Round 110: train accuracy=0.88437 test accuracy=0.75\n",
      "Round 111: train accuracy=0.8875 test accuracy=0.76562\n",
      "Round 112: train accuracy=0.8875 test accuracy=0.76562\n",
      "Round 113: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 114: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 115: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 116: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 117: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 118: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 119: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 120: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 121: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 122: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 123: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 124: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 125: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 126: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 127: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 128: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 129: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 130: train accuracy=0.89062 test accuracy=0.76562\n",
      "Round 131: train accuracy=0.89375 test accuracy=0.76562\n",
      "Round 132: train accuracy=0.89688 test accuracy=0.76562\n",
      "Round 133: train accuracy=0.89688 test accuracy=0.76562\n",
      "Round 134: train accuracy=0.89688 test accuracy=0.76562\n",
      "Round 135: train accuracy=0.89688 test accuracy=0.76562\n",
      "Round 136: train accuracy=0.89688 test accuracy=0.76562\n",
      "Round 137: train accuracy=0.89688 test accuracy=0.76562\n",
      "Round 138: train accuracy=0.9 test accuracy=0.76562\n",
      "Round 139: train accuracy=0.9 test accuracy=0.76562\n",
      "Round 140: train accuracy=0.9 test accuracy=0.76562\n",
      "Round 141: train accuracy=0.9 test accuracy=0.76562\n",
      "Round 142: train accuracy=0.9 test accuracy=0.76562\n",
      "Round 143: train accuracy=0.9 test accuracy=0.76562\n",
      "Round 144: train accuracy=0.9 test accuracy=0.76562\n",
      "Round 145: train accuracy=0.9 test accuracy=0.76562\n",
      "Round 146: train accuracy=0.9 test accuracy=0.76562\n",
      "Round 147: train accuracy=0.9 test accuracy=0.76562\n",
      "Round 148: train accuracy=0.9 test accuracy=0.76562\n",
      "Round 149: train accuracy=0.90312 test accuracy=0.76562\n",
      "Round 150: train accuracy=0.90312 test accuracy=0.76562\n",
      "Round 151: train accuracy=0.90312 test accuracy=0.76562\n",
      "Round 152: train accuracy=0.90312 test accuracy=0.76562\n",
      "Round 153: train accuracy=0.90312 test accuracy=0.76562\n",
      "Round 154: train accuracy=0.90312 test accuracy=0.76562\n",
      "Round 155: train accuracy=0.90312 test accuracy=0.76562\n",
      "Round 156: train accuracy=0.90625 test accuracy=0.76562\n",
      "Round 157: train accuracy=0.90625 test accuracy=0.76562\n",
      "Round 158: train accuracy=0.90625 test accuracy=0.76562\n",
      "Round 159: train accuracy=0.90625 test accuracy=0.76562\n",
      "Round 160: train accuracy=0.90625 test accuracy=0.76562\n",
      "Round 161: train accuracy=0.90625 test accuracy=0.76562\n",
      "Round 162: train accuracy=0.90625 test accuracy=0.76562\n",
      "Round 163: train accuracy=0.90625 test accuracy=0.76562\n",
      "Round 164: train accuracy=0.90625 test accuracy=0.76562\n",
      "Round 165: train accuracy=0.90625 test accuracy=0.76562\n",
      "Round 166: train accuracy=0.90938 test accuracy=0.76562\n",
      "Round 167: train accuracy=0.90938 test accuracy=0.76562\n",
      "Round 168: train accuracy=0.90938 test accuracy=0.76562\n",
      "Round 169: train accuracy=0.90938 test accuracy=0.76562\n",
      "Round 170: train accuracy=0.90938 test accuracy=0.76562\n",
      "Round 171: train accuracy=0.90938 test accuracy=0.76562\n",
      "Round 172: train accuracy=0.90938 test accuracy=0.76562\n",
      "Round 173: train accuracy=0.9125 test accuracy=0.76562\n",
      "Round 174: train accuracy=0.9125 test accuracy=0.76562\n",
      "Round 175: train accuracy=0.9125 test accuracy=0.76562\n",
      "Round 176: train accuracy=0.9125 test accuracy=0.76562\n",
      "Round 177: train accuracy=0.9125 test accuracy=0.76562\n",
      "Round 178: train accuracy=0.9125 test accuracy=0.76562\n",
      "Round 179: train accuracy=0.9125 test accuracy=0.76562\n",
      "Round 180: train accuracy=0.9125 test accuracy=0.76562\n",
      "Round 181: train accuracy=0.91562 test accuracy=0.76562\n",
      "Round 182: train accuracy=0.91562 test accuracy=0.76562\n",
      "Round 183: train accuracy=0.91562 test accuracy=0.76562\n",
      "Round 184: train accuracy=0.91562 test accuracy=0.76562\n",
      "Round 185: train accuracy=0.91562 test accuracy=0.76562\n",
      "Round 186: train accuracy=0.91562 test accuracy=0.76562\n",
      "Round 187: train accuracy=0.91562 test accuracy=0.76562\n",
      "Round 188: train accuracy=0.91875 test accuracy=0.76562\n",
      "Round 189: train accuracy=0.91875 test accuracy=0.76562\n",
      "Round 190: train accuracy=0.91875 test accuracy=0.76562\n",
      "Round 191: train accuracy=0.91875 test accuracy=0.76562\n",
      "Round 192: train accuracy=0.91875 test accuracy=0.76562\n",
      "Round 193: train accuracy=0.91875 test accuracy=0.76562\n",
      "Round 194: train accuracy=0.91875 test accuracy=0.76562\n",
      "Round 195: train accuracy=0.91875 test accuracy=0.76562\n",
      "Round 196: train accuracy=0.91875 test accuracy=0.76562\n",
      "Round 197: train accuracy=0.91875 test accuracy=0.76562\n",
      "Round 198: train accuracy=0.91875 test accuracy=0.76562\n",
      "Round 199: train accuracy=0.91875 test accuracy=0.76562\n"
     ]
    }
   ],
   "source": [
    "##Stage 3\n",
    "# Run TCT-Stage2\n",
    "for round_idx in range(num_rounds_stage3):\n",
    "    theta_list = []\n",
    "    for i in range(num_clients_stage3):\n",
    "        theta_hat_update, h_i_client_update = scaffold_update(grad_all[i],\n",
    "                                                              target_all[i],\n",
    "                                                              client_thetas[i],\n",
    "                                                              client_hi_s[i],\n",
    "                                                              theta_global,\n",
    "                                                              M=args[\"local_steps_stage2\"],\n",
    "                                                              lr_local=args[\"local_lr_stage2\"])\n",
    "        client_hi_s[i] = h_i_client_update * 1.0\n",
    "        client_thetas[i] = theta_hat_update * 1.0\n",
    "        theta_list.append(theta_hat_update)\n",
    "\n",
    "    # averaging\n",
    "    theta_global = torch.zeros_like(theta_list[0]) #supprimer .cuda()\n",
    "    for theta_idx in range(num_clients_stage3):\n",
    "        theta_global += (1.0 / num_clients_stage3) * theta_list[theta_idx]\n",
    "\n",
    "    # eval on train\n",
    "    logits_class_train = torch.cat(grad_all) @ theta_global #supprimer .cuda()\n",
    "    _, targets_pred_train = logits_class_train.max(1)\n",
    "    train_acc = targets_pred_train.eq(torch.cat(target_all)).sum() / (1.0 * logits_class_train.shape[0]) #supprimer .cuda()\n",
    "    # eval on test\n",
    "    logits_class_test = grad_eval @ theta_global\n",
    "    _, targets_pred_test = logits_class_test.max(1)\n",
    "    test_acc = targets_pred_test.eq(target_eval).sum() / (1.0 * logits_class_test.shape[0]) #supprimer .cuda()\n",
    "    print('Round 1%d: train accuracy=%0.5g test accuracy=%0.5g' % (round_idx, train_acc.item(), test_acc.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
